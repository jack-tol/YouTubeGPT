{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Multiple Regression, Clearly Explained!!!\n",
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 225\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    224\u001b[0m video_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=EkAQAi3a4js\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_video(video_url)\n",
      "Cell \u001b[1;32mIn[1], line 194\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(video_url, video_path, output_folder, interval)\u001b[0m\n\u001b[0;32m    191\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m+\u001b[39m interval\n\u001b[0;32m    192\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(analyze_image(base64_image, session, start_time, end_time))\n\u001b[1;32m--> 194\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[0;32m    197\u001b[0m     description \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:279\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 126\u001b[0m, in \u001b[0;36manalyze_image\u001b[1;34m(base64_image, session, start_time, end_time)\u001b[0m\n\u001b[0;32m     98\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m    123\u001b[0m }\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aiohttp\\client.py:1187\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[1;32m-> 1187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aiohttp\\client.py:601\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[0;32m    599\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m req\u001b[38;5;241m.\u001b[39msend(conn)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstart(conn)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m     resp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aiohttp\\client_reqrep.py:965\u001b[0m, in \u001b[0;36mClientResponse.start\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\n\u001b[1;32m--> 965\u001b[0m     message, payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m http\u001b[38;5;241m.\u001b[39mHttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[0;32m    969\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m         headers\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    973\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aiohttp\\streams.py:622\u001b[0m, in \u001b[0;36mDataQueue.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio\u001b[38;5;241m.\u001b[39mCancelledError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import cv2\n",
    "import moviepy.editor as mp\n",
    "import whisper\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter Notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "API_KEY = \"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\"\n",
    "\n",
    "# General utility functions\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"Converts time in seconds to MM:SS format.\"\"\"\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02}:{seconds:02}\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Encodes an image file to a base64 string.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Video processing functions\n",
    "def download_video(url, filename=\"video.mp4\"):\n",
    "    \"\"\"Downloads a YouTube video and returns the video title.\"\"\"\n",
    "    try:\n",
    "        yt = YouTube(url, on_progress_callback=on_progress)\n",
    "        print(f\"Downloading: {yt.title}\")\n",
    "        ys = yt.streams.get_highest_resolution()\n",
    "        ys.download(filename=filename)\n",
    "        return yt.title\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        return \"Unknown Title\"\n",
    "\n",
    "def extract_frames(video_path, output_folder, interval=10):\n",
    "    \"\"\"Extracts frames from a video at specified intervals.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    current_frame = 0\n",
    "    frame_count = 1  # Initialize frame counter\n",
    "    while current_frame < total_frames:\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, current_frame)\n",
    "        success, frame = video_capture.read()\n",
    "        if success:\n",
    "            output_filename = os.path.join(output_folder, f\"image_{frame_count}.jpg\")\n",
    "            cv2.imwrite(output_filename, frame)\n",
    "            frame_count += 1\n",
    "        else:\n",
    "            break\n",
    "        current_frame += interval * fps\n",
    "\n",
    "    video_capture.release()\n",
    "\n",
    "def transcribe_audio(video_path):\n",
    "    \"\"\"Extracts audio from video and transcribes it with timestamps.\"\"\"\n",
    "    try:\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        audio_path = \"audio.wav\"\n",
    "        video.audio.write_audiofile(audio_path)\n",
    "\n",
    "        model = whisper.load_model(\"base.en\")\n",
    "        result = model.transcribe(audio_path)\n",
    "\n",
    "        transcript_with_timestamps = [\n",
    "            f\"[{format_timestamp(segment['start'])} - {format_timestamp(segment['end'])}]: {segment['text']}\"\n",
    "            for segment in result['segments']\n",
    "        ]\n",
    "        return \"\\n\".join(transcript_with_timestamps)\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Asynchronous API request functions\n",
    "async def analyze_image(base64_image, session, start_time, end_time):\n",
    "    \"\"\"Sends an image to the OpenAI Vision API and retrieves a description.\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Describe in detail the visual content of the image provided. Focus on capturing both small details and the overall context. Avoid listing objects; instead, compose a coherent paragraph that conveys what is happening in the frame.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"This frame is from [{format_timestamp(start_time)} - {format_timestamp(end_time)}].\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"low\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 150\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload) as response:\n",
    "            return await response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return {\"choices\": [{\"message\": {\"content\": \"Error in processing the image\"}}]}\n",
    "\n",
    "async def aggregate_descriptions(descriptions, transcript, title):\n",
    "    \"\"\"Aggregates frame descriptions and transcript into a concise video summary, including the video title.\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "\n",
    "    content_to_send = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"Create a relatively concise summary of the video titled '{title}'. The summary should be no longer than three paragraphs and should seamlessly integrate both the visual elements and the spoken content from the transcript. Reference visual and audio elements naturally, using temporal cues to connect these domains into an immersive and accurate summary of the video content. Don't cite the timestamp as if it were an in-text citation, instead use a more linguistic approach, segueing between the audio components (from the transcript), visual components (from the descriptions), and the temporal data you have access to which is associated with the audio and visual components. Make it sound a bit more natural and human, and less like an AI. Less descriptive imagery, we aren't in highschool English class so we don't need to evaluate everything. Just use what you have and do a damn good summary.\"\"\"\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"\\n\".join(descriptions)},\n",
    "        {\"type\": \"text\", \"text\": f\"Transcript: {transcript}\"}\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content_to_send,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload) as response:\n",
    "                result = await response.json()\n",
    "                # Save the prompt content to a file\n",
    "                with open(\"prompt.txt\", \"w\") as prompt_file:\n",
    "                    prompt_file.write(str(payload))\n",
    "                return result['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error aggregating descriptions: {e}\")\n",
    "        return \"Error generating summary.\"\n",
    "\n",
    "# Main processing function\n",
    "async def process_video(video_url, video_path=\"video.mp4\", output_folder=\"images\", interval=10):\n",
    "    \"\"\"Main function to process video, extract frames, analyze images, transcribe audio, and generate a video summary.\"\"\"\n",
    "    try:\n",
    "        # Download the video and get its title\n",
    "        video_title = download_video(video_url, video_path)\n",
    "\n",
    "        # Extract frames from the video\n",
    "        extract_frames(video_path, output_folder, interval)\n",
    "\n",
    "        # Analyze each frame asynchronously\n",
    "        descriptions = []\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for i, image_file in enumerate(sorted(os.listdir(output_folder))):\n",
    "                image_path = os.path.join(output_folder, image_file)\n",
    "                base64_image = encode_image(image_path)\n",
    "                if not base64_image:\n",
    "                    continue\n",
    "\n",
    "                start_time = i * interval\n",
    "                end_time = start_time + interval\n",
    "                tasks.append(analyze_image(base64_image, session, start_time, end_time))\n",
    "\n",
    "            results = await asyncio.gather(*tasks)\n",
    "\n",
    "            for i, result in enumerate(results):\n",
    "                description = result['choices'][0]['message']['content']\n",
    "                start_time = i * interval\n",
    "                end_time = start_time + interval\n",
    "                descriptions.append(f\"[{format_timestamp(start_time)} - {format_timestamp(end_time)}]: {description}\")\n",
    "\n",
    "        # Extract and transcribe audio with timestamps\n",
    "        transcription = transcribe_audio(video_path)\n",
    "\n",
    "        # Generate the final summary\n",
    "        summary = await aggregate_descriptions(descriptions, transcription, video_title)\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video: {e}\")\n",
    "    finally:\n",
    "        # Cleanup temporary files and folders (except video)\n",
    "        try:\n",
    "            if os.path.exists(\"audio.wav\"):\n",
    "                os.remove(\"audio.wav\")\n",
    "            if os.path.exists(output_folder):\n",
    "                for image_file in os.listdir(output_folder):\n",
    "                    os.remove(os.path.join(output_folder, image_file))\n",
    "                os.rmdir(output_folder)\n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"Error during cleanup: {cleanup_error}\")\n",
    "\n",
    "# Example usage\n",
    "video_url = \"https://www.youtube.com/watch?v=EkAQAi3a4js\"\n",
    "await process_video(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
